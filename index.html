<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="description" content="Design & Learning Research Group Solution for euROBIN MSVC @ IROS 2024" />
  <meta name="keywords" content="Design & Learning Research Group, euROBIN, MSVC, IROS 2024" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>
    Transferrable Robot Skills Approaching Human-Level Versatility in Automated Task Board Manipulation - Design &
    Learning Research Group
  </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

  <link rel="stylesheet" href="css/bulma.min.css" />
  <link rel="stylesheet" href="css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="css/bulma-slider.min.css" />
  <link rel="stylesheet" href="css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="css/index.css" />
  <link rel="icon" href="./images/favicon.ico" type="image/x-icon" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="js/fontawesome.all.min.js"></script>
  <script src="js/bulma-carousel.min.js"></script>
  <script src="js/bulma-slider.min.js"></script>
  <script src="js/index.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-WCPLFB8FXC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-WCPLFB8FXC');
  </script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-3 publication-title">
              Solution for euROBIN MSVC @ IROS 2024
            </h2>
            <h1 class="title is-2 publication-title">
              Transferrable Robot Skills Approaching Human-Level Versatility in Automated Task Board Manipulation
            </h1>
            <h2 class="title is-4 publication-title-award">
              Fastest Automated Task Board Solution Award
            </h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Design and Learning Research Group (DLRG)
                <br />
                Southern Univerisity of Science and Technology
              </span>
            </div>
            <table align="center" class="table">
              <tr>
                <td>
                  <a href="https://www.sustech.edu.cn/en/">
                    <img src="./images/logo/sustech_light.png" width="300px" alt="SUSTech"></img>
                  </a>
                </td>
                <td>
                  <a href="https://bionicdl.ancorasir.com">
                    <img src="./images/logo/bionicdl.jpg" width="70px" alt="BionicDL"></img>
                  </a>
                </td>
                <td>
                  <a href="https://maindl.ancorasir.com">
                    <img src="./images/logo/maindl.jpg" width="70px" alt="MainDL"></img>
                  </a>
                </td>
              </tr>
            </table>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- ArXiv Link. -->
                <!-- <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>ArXiv</span>
                  </a>
                </span> -->
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://youtu.be/6FlQ3zCi53w" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/ancorasir/DesignLearnRG_euROBIN"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Data Link. -->
                <span class="link-block">
                  <a href="https://drive.google.com/drive/folders/1yhIDuubmL7S85B2c-S1hvZppHv4G-Wow?usp=sharing"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
                <!-- zh-CN Link. -->
                <!-- <span class="link-block">
                  <a href="https://msvc-dlrg.github.io/zh-cn" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-globe"></i>
                    </span>
                    <span>中文</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="content has-text-centered">
        <img src="./images/teaser.png" alt="Teaser" width="1000px" />
      </div>
      <div class="container">
        <div id="results-carousel-hero" class="carousel results-carousel">
          <div class="item">
            <img src="./images/on-site/hero_1.jpg" alt="On-site 1" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_2.jpg" alt="On-site 2" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_3.jpg" alt="On-site 3" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_4.jpg" alt="On-site 4" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_5.jpg" alt="On-site 5" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_6.jpg" alt="On-site 6" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_7.jpg" alt="On-site 7" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_8.jpg" alt="On-site 8" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_9.jpg" alt="On-site 9" />
          </div>
          <div class="item">
            <img src="./images/on-site/hero_10.jpg" alt="On-site 10" />
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview</h2>
          <div class="content has-text-justified">
            <p>
              Versatility in engineering means adaptability and multi-functionality. For robotic automation, it
              signifies the ability to handle diverse tasks, easily switch between different operations, and thrive in
              changing environments. The current gap lies in developing agreed-upon frameworks and metrics that are both
              quantitative and context-appropriate, capturing not just mechanical capabilities but also cognitive
              adaptability, integration complexity, and economic value.
            </p>
            <p>
              In this paper, we present the Design and Learning Research Group's (DLRG) solution for the <a
                href="https://sites.google.com/view/eurobin-msvc">euROBIN Manipulation Skill Versatility Challenge
                (MSVC)</a> at <a href="https://iros2024-abudhabi.org">IROS 2024</a> in Abu Dhabi, UAE. The MSVC, held
              annually since 2021, is part of the euROBIN project that seeks to advance transferrable robot skills for
              the circular economy by autonomously performing tasks such as object localization, insertion, door
              operation, circuit probing, and cable management. We approached the standardized task board provided by
              event organizers that mimics industrial testing procedures by structurally decomposing the task into
              subtask skills. We created a custom dashboard with drag-and-drop code blocks to streamline development and
              adaptation, enabling rapid code refinement and task restructuring, complementing the default remote web
              platform that records the performance. Our system completed the task board in 28.2 sec in the lab (37.2
              sec on-site), nearly tripling the efficiency over the averaged best time of 83.5 sec by previous teams and
              bringing performance closer to a human baseline of 16.3 sec. By implementing subtasks as reusable code
              blocks, we facilitated the transfer of these skills to a distinct scenario, successfully removing a
              battery from a smoke detector with minimal reconfiguration.
            </p>
            <p>
              We also provide suggestions for future research and industrial practice on robotic versatility in
              manipulation automation through globalized competitions, interdisciplinary efforts, standardization
              initiatives, and iterative testing in the real world to ensure that it is measured in a meaningful,
              actionable way.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/6FlQ3zCi53w?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Robot System Design</h2>
          <div class="content has-text-justified">
            <p>
              The robot system developed by DLRG for the competition includes a robot arm (UR10e, Universal Robots), a
              camera (D435, Intel RealSense), a gripper (Hand-E, Robotiq), and a pair of 3D-printed fingertips with
              minor customization for cable handling, all mounted on the open-sourced <a
                href="https://doi.org/10.1109/AIM43001.2020.9159011">DeepClaw</a> station previously developed by the
              team for a reliable and reconfigurable implementation. The camera was mounted on a bracket between the
              gripper and the flange of the robot arm.
            </p>
          </div>
          <table align="center" width="100%" border="1">
            <tr>
              <th width="20%">Equipment</th>
              <th width="30%">Image</th>
              <th width="50%">Description</th>
            </tr>
            <tr>
              <td style="vertical-align: middle">
                <a href="https://www.universal-robots.com/products/ur10-robot">
                  UR10e Cobot
                </a>
              </td>
              <td style="vertical-align: middle">
                <img src="./images/hardware/ur10e.png" alt="UR10e" width="60%" />
              </td>
              <td style="vertical-align: middle">
                The UR10e cobot is mounted on the open-sourced <a
                  href="https://doi.org/10.1109/AIM43001.2020.9159011">DeepClaw</a> station and controlled through the
                real-time data exchange (RTDE) interface by the laptop.
              </td>
            </tr>
            <tr>
              <td style="vertical-align: middle">
                <a href="https://robotiq.com/products/adaptive-grippers#Hand-E">
                  Robotiq Hand-E gripper
                </a>
              </td>
              <td style="vertical-align: middle">
                <img src="./images/hardware/hand-e.png" alt="Hand-E" width="40%" />
              </td>
              <td style="vertical-align: middle">
                The Hand-E gripper is mounted on the tool flange of the UR10e cobot and controlled via the Modbus RTU
                RS485 protocol.
              </td>
            </tr>
            <tr>
              <td style="vertical-align: middle">
                <a href="https://cad.onshape.com/documents/43edc50e275c72eace7a4839">
                  3D-printed fingertips
                </a>
              </td>
              <td style="vertical-align: middle">
                <img src="./images/hardware/fingertip.png" alt="3D-printed fingertips" width="70%" />
              </td>
              <td style="vertical-align: middle">
                The fingertips are re-designed based on the original fingertips of the Robotiq Hand-E gripper to adapt
                to the competition tasks by adding grooves. They are fabricated using nylon (PA12, HP) through multi-jet
                fusion (MJF)
              </td>
            </tr>

            <tr>
              <td style="vertical-align: middle">
                <a href="https://www.intelrealsense.com/depth-camera-d435i">
                  Intel Realsense D435i camera
                </a>
              </td>
              <td style="vertical-align: middle">
                <img src="./images/hardware/d435i.png" alt="Realsense D435i" width="80%" />
              </td>
              <td style="vertical-align: middle">
                The Realsense D435i RGB-D camera is mounted on the UR10e cobot
                through a bracket and connected to the laptop through a USB
                cable.
              </td>
            </tr>

            <tr>
              <td style="vertical-align: middle">
                <a href="https://cad.onshape.com/documents/01d4267b0af8aab9d6acb1ab">
                  Camera bracket
                </a>
              </td>
              <td style="vertical-align: middle">
                <img src="./images/hardware/camera_bracket.png" alt="Camera bracket" width="80%" />
              </td>
              <td style="vertical-align: middle">
                The camera bracket is designed to mount the Realsense D435i
                RGB-D camera on the UR10e cobot. It is frabricated by CNC with
                Al6061.
              </td>
            </tr>

            <tr>
              <td style="vertical-align: middle">
                <a href="https://www.zhiyun-tech.com/en/product/detail/867">
                  ZHIYUN FIVERAY M20 fill light
                </a>
                (Optinal)
              </td>
              <td style="vertical-align: middle">
                <img src="./images/hardware/fiveray-m20.png" alt="FIVERAY M20" width="70%" />
              </td>
              <td style="vertical-align: middle">
                The ZHIYUN FIVERAY M20 fill light is mounted on the camera to
                provide sufficient illumination. It is up to 2010 Lux (0.5m)
                and able to work for more than 40 minutes without charging.
              </td>
            </tr>
          </table>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Solution</h2>
          <h3 class="title is-4">Task 1-1: Task Board Pose Estimation</h3>
          <div class="content has-text-justified">
            <p>
              The task board is placed at a random orientation on two velcro
              strips to hold it in place for a trial. Therefore, for all
              subsequent tasks, the task board needs to be localized. We use
              fine-tuned YOLOv8 to detect the red button, blue button and the
              red test port. As the positional relationship between these task
              board elements is known and fixed, we can estimate the global 6D
              pose (relative to the robot base) of the board.
            </p>
          </div>
          <div class="columns is-centered">
            <div class="column is-half">
              <img src="./images/pose_yolo.png" alt="Task Board Pose Estimation" width="100%" />
            </div>
            <div class="column is-half">
              <img src="./images/pose_ref.png" alt="Task Board Pose Relative to Robot Base" width="100%" />
            </div>
          </div>
          <h3 class="title is-4">Task 1-2: Press Blue Button</h3>
          <div class="content has-text-justified">
            <p>
              To press the button, we first command the gripper to go right
              over it and then lower the gripper position. Then the gripper
              goes upward, preparing for the next task.
            </p>
          </div>
          <div class="content">
            <img src="./images/blue_button.png" alt="Press Blue Button" width="100%" />
          </div>
          <h3 class="title is-4">
            Task 2: Move Slider to Setpoints on Screen
          </h3>
          <div class="content has-text-justified">
            <p>
              After the gripper approaches to and securely grips the slider,
              we detect the screen using another fine-tuned YOLOv8. The pixels
              of the triangles displayed on the screen are extracted based on
              their color to calculate the pixel distance error, which is then
              projected to the actual distance to move along the slider track.
            </p>
          </div>
          <div class="columns is-centered">
            <div class="column is-half">
              <img src="./images/slider_screen.png" alt="Screen Detection by YOLOv8" width="100%" />
            </div>
            <div class="column is-half">
              <video id="teaser" autoplay muted loop width="100%">
                <source src="./videos/move_slider.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <h3 class="title is-4">Task 3: Plug in Probe into Test Port</h3>
          <div class="content has-text-justified">
            <p>
              We first move the gripper above the left probe, lower it down to
              grip it. Although we do not estimate the precise orientation of
              the probe, we find it robust enough to set a fixed rotation of
              the gripper, since the probe orientation will be aligned with
              the gripper after the gripper closes. To increase the
              determinism of the cable wrapping task, we rotate the probe to a
              known angle after plug it into the test port.
            </p>
          </div>
          <div class="content">
            <img src="./images/plug_in_probe.png" alt="Plug in Probe into Test Port" width="100%" />
          </div>
          <h3 class="title is-4">Task 4: Open Door, Probe Circuit</h3>
          <div class="content has-text-justified">
            <p>
              To speed up the task execution, the gripper first pulls out the
              probe, inserts the probe tip into the gap of the door edges to
              open it. Then the probe is inserted into the testing slot and is
              put back to the probe slot. The task is challenging as the probe
              may change its pose due to the contact with the task board, but
              the grooves of the fingertips we design helps the gripper to
              securely grasp the probe, dramatically increase the accuracy and
              robustness of the manipulation process.
            </p>
          </div>
          <div class="content">
            <video id="teaser" autoplay muted loop width="100%">
              <source src="./videos/probe_circuit.mp4" type="video/mp4">
            </video>
          </div>
          <h3 class="title is-4">Task 5: Wrap Cable, Replace Probe</h3>
          <div class="content has-text-justified">
            <p>
              To wrap the cable, we collect the gripper poses from human
              demonstrated motions, and transform the poses to the task board
              frame, making it invariant to the absolute position and
              orientation of the board.
            </p>
          </div>
          <div class="content">
            <video id="teaser" autoplay muted loop width="100%">
              <source src="./videos/wrap_cable.mp4" type="video/mp4">
            </video>
          </div>
          <h3 class="title is-4">Task 6: Press Stop Trial Button</h3>
          <div class="content has-text-justified">
            <p>
              Pressing the stop trial button (red button) is similar as
              pressing the blue button. Finally, the robot gripper Presses the
              red button to finish the trial.
            </p>
          </div>
          <div class="content">
            <img src="./images/stop_trial_button.png" alt="Press Stop Trial Button" width="100%" />
          </div>
        </div>
      </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Continuous Trials</h2>
          <div class="content has-text-justified">
            <p>
              Here are 5 continuous trials with random initial poses of the
              task board, showing the robustness of our solution.
            </p>
          </div>
          <div class="content">
            <video id="teaser" autoplay muted loop controls width="100%">
              <source src="./videos/continuous_trials.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Fastest Trial</h2>
          <div class="content has-text-justified">
            <p>
              Here is the fastest trial we have achieved according to the record
              by the web board. The total trial time is 28.17s.
            </p>
          </div>
          <div class="content">
            <video id="teaser" autoplay muted loop controls width="100%">
              <source src="./videos/fastest_trial.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Skill Transferability</h2>
          <div class="content has-text-justified">
            <p>
              We transfer the skill to battery extraction of smoke alarm. The
              battery's pose is detected using YOLOv8 with the image captured
              by the camera. The gripper go through the demonstrated trajectories
              to lift up and grasp the battery and place beside the smoke alarm.
              To pick up the new battery, the robot goes above it and the pose is
              also detected by YOLOv8. The gripper pick up the battery and place into
              the containers.
            </p>
          </div>
          <div class="content">
            <video id="teaser" autoplay muted loop controls width="100%">
              <source src="./videos/battery_extraction.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section is-small">
    <div class="container is-max-desktop">
      <div class="container has-text-centered">
        <h2 class="title is-3 is-size-4-mobile">Our Team</h2>
        <div class="publication-authors is-flex justify-content is-justify-content-space-around is-hidden-mobile">
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-128x128">
              <a href="https://hanxudong.cc">
                <img class="is-rounded" src="./images/team/xudong.jpg" alt="Xudong Han">
              </a>
            </figure>
            <a href="https://hanxudong.cc">Xudong Han</a><sup>1</sup>
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-128x128">
              <a href="https://github.com/AlanSunHR">
                <img class="is-rounded" src="./images/team/haoran.jpg" alt="Haoran Sun">
              </a>
            </figure>
            <a href="https://github.com/AlanSunHR">Haoran Sun</a><sup>1, 2</sup>
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-128x128">
              <a href="https://gabriel-ning.github.io">
                <img class="is-rounded" src="./images/team/ning.jpg" alt="Ning Guo">
              </a>
            </figure>
            <a href="https://gabriel-ning.github.io">Ning Guo</a><sup>1</sup>
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-128x128">
              <a href="https://geshengpsn.github.io/">
                <img class="is-rounded" src="./images/team/sheng.jpg" alt="Sheng Ge">
              </a>
            </figure>
            <a href="https://geshengpsn.github.io/">Sheng Ge</a><sup>1</sup>
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-128x128">
              <a href="https://bionicdl.ancorasir.com">
                <img class="is-rounded" src="./images/team/chaoyang.jpg" alt="Chaoyang Song">
              </a>
            </figure>
            <a href="https://bionicdl.ancorasir.com">Chaoyang Song</a><sup>1, </sup>*
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-128x128">
              <a href="https://maindl.ancorasir.com">
                <img class="is-rounded" src="./images/team/fang.jpg" alt="Fang Wan">
              </a>
            </figure>
            <a href="https://maindl.ancorasir.com">Fang Wan</a><sup>1, </sup>*
          </div>
        </div>

        <div class="is-flex is-flex-direction-row is-flex-wrap-wrap is-justify-content-space-evenly is-hidden-tablet">
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-96x96">
              <a href="https://hanxudong.cc">
                <img class="is-rounded" src="./images/team/xudong.jpg" alt="Xudong Han">
              </a>
            </figure>
            <a href="https://hanxudong.cc">Xudong Han</a><sup>1</sup>
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-96x96">
              <a href="https://github.com/AlanSunHR">
                <img class="is-rounded" src="./images/team/haoran.jpg" alt="Haoran Sun">
              </a>
            </figure>
            <a href="https://github.com/AlanSunHR">Haoran Sun</a><sup>1, 2</sup>
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-96x96">
              <a href="https://gabriel-ning.github.io">
                <img class="is-rounded" src="./images/team/ning.jpg" alt="Ning Guo">
              </a>
            </figure>
            <a href="https://gabriel-ning.github.io">Ning Guo</a><sup>1</sup>
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-96x96">
              <a href="https://geshengpsn.github.io/">
                <img class="is-rounded" src="./images/team/sheng.jpg" alt="Sheng Ge">
              </a>
            </figure>
            <a href="https://geshengpsn.github.io/">Sheng Ge</a><sup>1</sup>
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-96x96">
              <a href="https://bionicdl.ancorasir.com">
                <img class="is-rounded" src="./images/team/chaoyang.jpg" alt="Chaoyang Song">
              </a>
            </figure>
            <a href="https://bionicdl.ancorasir.com">Chaoyang Song</a><sup>1,</sup>*
          </div>
          <div class="author-block has-text-centered has-addons-centered">
            <figure class="image is-96x96">
              <a href="https://maindl.ancorasir.com">
                <img class="is-rounded" src="./images/team/fang.jpg" alt="Fang Wan">
              </a>
            </figure>
            <a href="https://maindl.ancorasir.com">Fang Wan</a><sup>1,</sup>*
          </div>
        </div>
        <div class="publication-authors">
          <span class="author-block"><sup>1</sup>Southern University of Science and Technology, </span>
          <span class="author-block"><sup>2</sup>University of Hongkong, </span>
          <span class="author-block">*Corresponding Author</span>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              Website template credit to
              <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, and is licensed under a
              <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons
                Attribution-ShareAlike 4.0 International
                License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    bulmaCarousel.attach('#results-carousel-hero', {
      slidesToScroll: 1,
      slidesToShow: 3,
      autoplay: true,
      loop: true,
      infinite: true,
      duration: 500,
      autoplaySpeed: 5000,
    });

    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
</body>

</html>