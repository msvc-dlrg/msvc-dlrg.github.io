<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Design and Learning Research Group Submission - euROBIN MSVC @ IROS 2024</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="css/bulma.min.css">
  <link rel="stylesheet" href="css/bulma-carousel.min.css">
  <link rel="stylesheet" href="css/bulma-slider.min.css">
  <link rel="stylesheet" href="css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="css/index.css">
  <link rel="icon" href="images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="js/fontawesome.all.min.js"></script>
  <script src="js/bulma-carousel.min.js"></script>
  <script src="js/bulma-slider.min.js"></script>
  <script src="js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">Design and Learning Research Group Submission</h1>
            <h2 class="title is-3 publication-title">euROBIN MSVC @ IROS 2024</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://bionicdl.ancorasir.com">Chaoyang Song</a>,
              </span>
              <span class="author-block">
                <a href="https://gabriel-ning.github.io">Ning Guo</a>,
              </span>
              <span class="author-block">
                <a href="">Haoran Sun</a>
              </span>
              <span class="author-block">
                <a href="https://hanxudong.cc">Xudong Han</a>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Southern University of Science and Technology</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/ancorasir/DesignLearnRG_euROBIN"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="videos/teaser.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview</h2>
          <div class="content has-text-justified">
            <p>
              We present the first method capable of photorealistically reconstructing a non-rigidly
              deforming scene using photos/videos captured casually from mobile phones.
            </p>
            <p>
              Our approach augments neural radiance fields
              (NeRF) by optimizing an
              additional continuous volumetric deformation field that warps each observed point into a
              canonical 5D NeRF.
              We observe that these NeRF-like deformation fields are prone to local minima, and
              propose a coarse-to-fine optimization method for coordinate-based models that allows for
              more robust optimization.
              By adapting principles from geometry processing and physical simulation to NeRF-like
              models, we propose an elastic regularization of the deformation field that further
              improves robustness.
            </p>
            <p>
              We show that <span class="dnerf">Nerfies</span> can turn casually captured selfie
              photos/videos into deformable NeRF
              models that allow for photorealistic renderings of the subject from arbitrary
              viewpoints, which we dub <i>"nerfies"</i>. We evaluate our method by collecting data
              using a
              rig with two mobile phones that take time-synchronized photos, yielding train/validation
              images of the same pose at different viewpoints. We show that our method faithfully
              reconstructs non-rigidly deforming scenes and reproduces unseen views with high
              fidelity.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Robot Platform</h2>
          <div class="content has-text-justified">
            <p>
              The robot system used in the competition consists of a UR10e collebrative robot, a 
              Robotiq Hand-E gripper, a pair of 3D-printed fingertips, a Realsense D435i RGB-D 
              camera, a camera bracket, and a ZHIYUN FIVERAY M20 fill light.
            </p>
          </div>
          <table align="center" width="80%" border="1">
            <tr>
              <th width="20%">Equipment</th>
              <th width="30%">Image</th>
              <th width="50%">Description</th>
            </tr>
            <tr>
              <td style="vertical-align: middle;">
                <a href="https://www.universal-robots.com/products/ur10-robot">
                  UR10e Cobot
                </a>
              </td>
              <td style="vertical-align: middle;">
                <img src="images/ur10e.png" alt="UR10e" width="60%">
              </td>
              <td style="vertical-align: middle;">
                The UR10e cobot is mounted with the table and controlled through the real-time 
                data exchange (RTDE) interface by the computer.
              </td>
            </tr>
            <tr>
              <td style="vertical-align: middle;">
                <a href="https://robotiq.com/products/adaptive-grippers#Hand-E">
                    Robotiq Hand-E gripper
                </a>
            </td>
              <td style="vertical-align: middle;">
                <img src="images/hand-e.png" alt="Hand-E" width="40%">
              </td>
              <td style="vertical-align: middle;">
                The Hand-E gripper is mounted on the tool flange of the UR10e cobot and controlled
                via the Modbus RTU protocol by the computer.
              </td>
            </tr>
            <tr>
              <td style="vertical-align: middle;">
                3D-printed fingertips
            </td>
              <td style="vertical-align: middle;">
                <img src="images/fingertip.png" alt="3D-printed fingertips" width="70%">
              </td>
              <td style="vertical-align: middle;">
                The fingertips are re-designed based on the original fingertips of the
                Robotiq Hand-E gripper to adapt to the competition tasks by adding grooves. They
                are 3D-printed with nylon (HP PA12).
            </tr>
            <tr>
              <td style="vertical-align: middle;">
                <a href="https://www.intelrealsense.com/depth-camera-d435i">
                    Intel Realsense D435i camera
                </a>
            </td>
              <td style="vertical-align: middle;">
                <img src="images/d435i.png" alt="Realsense D435i" width="80%">
              </td>
              <td style="vertical-align: middle;">
                The Realsense D435i RGB-D camera is mounted on the UR10e cobot through a bracket
                and connected to the computer through a USB cable.
            </tr>
            <tr>
              <td style="vertical-align: middle;">
                Camera bracket
            </td>
              <td style="vertical-align: middle;">
                <img src="images/camera_bracket.png" alt="Camera bracket" width="80%">
              </td>
              <td style="vertical-align: middle;">
                The camera bracket is designed to mount the Realsense D435i RGB-D camera on the UR10e
                cobot. It is frabricated by CNC with Al6061.
            </tr>
            <tr>
              <td style="vertical-align: middle;">
                <a href="https://www.zhiyun-tech.com/en/product/detail/867">
                    ZHIYUN FIVERAY M20 fill light
                </a>
              </td>
              <td style="vertical-align: middle;">
                <img src="images/fiveray-m20.png" alt="FIVERAY M20" width="70%">
              </td>
              <td style="vertical-align: middle;">
                The ZHIYUN FIVERAY M20 fill light is mounted on the camera to provide sufficient
                illumination. It is up to 20W and powered by a USB cable.
              </td>
            </tr>
          </table>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        Website template credit to 
                        <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, 
                        and is licensed under a 
                        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
  </footer>
</body>
</html>
